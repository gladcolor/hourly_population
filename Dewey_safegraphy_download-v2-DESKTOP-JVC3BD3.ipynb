{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T20:59:22.045911Z",
     "iopub.status.busy": "2024-01-28T20:59:22.044912Z",
     "iopub.status.idle": "2024-01-28T20:59:30.369450Z",
     "shell.execute_reply": "2024-01-28T20:59:30.368945Z",
     "shell.execute_reply.started": "2024-01-28T20:59:22.045911Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import base64 \n",
    "import tempfile\n",
    "from urllib.parse import urlparse\n",
    "from urllib.parse import unquote\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from getpass import getpass\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import random\n",
    "import sqlite3 \n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import Advan_operator as ad_op  \n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "access_token = 'ALtAyMZA.Y1sITQvTj6OXSr6XUz31P2ov3XvsdkhpbijDutzY0glCVNohhzM4okEe'\n",
    "\n",
    "import logging\n",
    "# Create a logger\n",
    "logger_name = 'all_logger'\n",
    "logger = logging.getLogger(logger_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T20:30:01.786318Z",
     "iopub.status.busy": "2024-01-27T20:30:01.785319Z",
     "iopub.status.idle": "2024-01-27T20:30:01.849784Z",
     "shell.execute_reply": "2024-01-27T20:30:01.848813Z",
     "shell.execute_reply.started": "2024-01-27T20:30:01.786318Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def safe_file_write(file_path, content):\n",
    "    # Create a temporary file in the same directory as the target file\n",
    "    dir_name = os.path.dirname(file_path)\n",
    "    with tempfile.NamedTemporaryFile(mode='wb', dir=dir_name, delete=False) as temp_file:\n",
    "        try:\n",
    "            # Write the content to the temporary file\n",
    "            temp_file.write(content)\n",
    "            temp_file.flush()\n",
    "            os.fsync(temp_file.fileno())\n",
    "            temp_file.close()\n",
    "\n",
    "            # Rename the temporary file to the target file (atomic operation)\n",
    "            os.replace(temp_file.name, file_path)\n",
    "        except Exception as e:\n",
    "            # Handle the exception (e.g., log it, raise it, or silently ignore it)\n",
    "            print(f\"An error occurred while writing the file: {e}\")\n",
    "            os.unlink(temp_file.name)\n",
    "        else:\n",
    "            print(\"File successfully written.\")\n",
    "\n",
    "def combine_monthly_pattern_home_panel_summary(data_dir, extend='.csv.gz'):\n",
    "    print(os.path.join(data_dir, f\"*{extend}\"))\n",
    "    all_files = glob(os.path.join(data_dir, f\"*{extend}\"))\n",
    "\n",
    "    df = pd.concat([pd.read_csv(f) for f in tqdm(all_files)])\n",
    "\n",
    "    return df\n",
    "    \n",
    "    # print(all_files)\n",
    "\n",
    "# Merge CSV files\n",
    "# home_panel_dir = r'F:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary'\n",
    "# home_panel_dir = r'F:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary_2023-11-23'\n",
    "# df = combine_monthly_pattern_home_panel_summary(data_dir=home_panel_dir)\n",
    "# df.to_csv(r'F:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_home_panel_summary_2019_2023.csv', index=False)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T20:37:50.652122Z",
     "iopub.status.busy": "2024-01-27T20:37:50.651120Z",
     "iopub.status.idle": "2024-01-27T20:37:50.712718Z",
     "shell.execute_reply": "2024-01-27T20:37:50.712718Z",
     "shell.execute_reply.started": "2024-01-27T20:37:50.652122Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# neighborhood patterns:\n",
    "url = r'https://app.deweydata.io/external-api/v3/products/2dfcb598-6e30-49f1-bdba-1deae113a951/files'\n",
    "# save_dir = r'K:\\SafeGraph\\Advan_2023_API\\Neighborhood_Patterns'   # Dell 2019\n",
    "# save_dir = r'F:\\SafeGraph\\Advan_2023_API\\Neighborhood_Patterns'  # Lenova 2018\n",
    "\n",
    "\n",
    "save_dir = r'D:\\SafeGraph\\Advan_2024_API\\Neighborhood_Patterns'  # Desktop 2018\n",
    "\n",
    "\n",
    "# monthly patterns:\n",
    "# url = r\"https://app.deweydata.io/external-api/v3/products/5acc9f39-1ca6-4535-b3ff-38f6b9baf85e/files\"\n",
    "# save_dir = r'K:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns2'\n",
    "\n",
    "# # weekly patterns:\n",
    "# url = r\"https://app.deweydata.io/external-api/v3/products/176f0262-c1f6-4dbe-be43-6a6eb21bcf8a/files\"\n",
    "# save_dir = r'K:\\SafeGraph\\Advan_2023_API\\Weekly_Patterns'\n",
    "\n",
    "# # hourly weather:\n",
    "# url = r\"https://app.deweydata.io/external-api/v3/products/a6be0385-8820-4943-a509-6eac4154b4f6/files\"\n",
    "\n",
    "# monthly home panel summary\n",
    "# url = r'https://app.deweydata.io/external-api/v3/products/8546740c-b0e9-4556-abb9-4bea2cca9ac9/files'\n",
    "# save_dir = r'F:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary'\n",
    "\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "# set key and API endpoint variables\n",
    "API_KEY = access_token\n",
    "PRODUCT_API_PATH = url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(r'F:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_home_panel_summary_2019_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sort_values(['YEAR', 'MON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T20:46:24.557349Z",
     "iopub.status.busy": "2024-01-27T20:46:24.556342Z",
     "iopub.status.idle": "2024-01-27T20:46:25.767110Z",
     "shell.execute_reply": "2024-01-27T20:46:25.767110Z",
     "shell.execute_reply.started": "2024-01-27T20:46:24.557349Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>partition_key</th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_extension</th>\n",
       "      <th>file_size_bytes</th>\n",
       "      <th>modified_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>Neighborhood_Patterns_US-0-DATE_RANGE_START-20...</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>209765982</td>\n",
       "      <td>2023-12-13T15:22:59.850Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>Neighborhood_Patterns_US-1-DATE_RANGE_START-20...</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>209763766</td>\n",
       "      <td>2023-12-13T15:23:43.303Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>Neighborhood_Patterns_US-2-DATE_RANGE_START-20...</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>209740187</td>\n",
       "      <td>2023-12-13T15:24:47.104Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>Neighborhood_Patterns_US-3-DATE_RANGE_START-20...</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>209729883</td>\n",
       "      <td>2023-12-13T15:25:25.804Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>Neighborhood_Patterns_US-4-DATE_RANGE_START-20...</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>209730076</td>\n",
       "      <td>2023-12-13T15:26:07.832Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>Neighborhood_Patterns_US-5-DATE_RANGE_START-20...</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>209781912</td>\n",
       "      <td>2023-12-13T15:26:53.278Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>Neighborhood_Patterns_US-6-DATE_RANGE_START-20...</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>209772073</td>\n",
       "      <td>2023-12-13T15:27:35.176Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>Neighborhood_Patterns_US-7-DATE_RANGE_START-20...</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>209781740</td>\n",
       "      <td>2023-12-13T15:28:18.993Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>Neighborhood_Patterns_US-8-DATE_RANGE_START-20...</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>209730193</td>\n",
       "      <td>2023-12-13T15:29:18.477Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>Neighborhood_Patterns_US-9-DATE_RANGE_START-20...</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>160682399</td>\n",
       "      <td>2023-12-13T15:32:23.418Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link partition_key  \\\n",
       "0  https://s3.us-east-005.backblazeb2.com/amplify...    2023-05-01   \n",
       "0  https://s3.us-east-005.backblazeb2.com/amplify...    2023-05-01   \n",
       "0  https://s3.us-east-005.backblazeb2.com/amplify...    2023-05-01   \n",
       "0  https://s3.us-east-005.backblazeb2.com/amplify...    2023-05-01   \n",
       "0  https://s3.us-east-005.backblazeb2.com/amplify...    2023-05-01   \n",
       "0  https://s3.us-east-005.backblazeb2.com/amplify...    2023-05-01   \n",
       "0  https://s3.us-east-005.backblazeb2.com/amplify...    2023-05-01   \n",
       "0  https://s3.us-east-005.backblazeb2.com/amplify...    2023-05-01   \n",
       "0  https://s3.us-east-005.backblazeb2.com/amplify...    2023-05-01   \n",
       "0  https://s3.us-east-005.backblazeb2.com/amplify...    2023-05-01   \n",
       "\n",
       "                                           file_name file_extension  \\\n",
       "0  Neighborhood_Patterns_US-0-DATE_RANGE_START-20...        .csv.gz   \n",
       "0  Neighborhood_Patterns_US-1-DATE_RANGE_START-20...        .csv.gz   \n",
       "0  Neighborhood_Patterns_US-2-DATE_RANGE_START-20...        .csv.gz   \n",
       "0  Neighborhood_Patterns_US-3-DATE_RANGE_START-20...        .csv.gz   \n",
       "0  Neighborhood_Patterns_US-4-DATE_RANGE_START-20...        .csv.gz   \n",
       "0  Neighborhood_Patterns_US-5-DATE_RANGE_START-20...        .csv.gz   \n",
       "0  Neighborhood_Patterns_US-6-DATE_RANGE_START-20...        .csv.gz   \n",
       "0  Neighborhood_Patterns_US-7-DATE_RANGE_START-20...        .csv.gz   \n",
       "0  Neighborhood_Patterns_US-8-DATE_RANGE_START-20...        .csv.gz   \n",
       "0  Neighborhood_Patterns_US-9-DATE_RANGE_START-20...        .csv.gz   \n",
       "\n",
       "   file_size_bytes               modified_at  \n",
       "0        209765982  2023-12-13T15:22:59.850Z  \n",
       "0        209763766  2023-12-13T15:23:43.303Z  \n",
       "0        209740187  2023-12-13T15:24:47.104Z  \n",
       "0        209729883  2023-12-13T15:25:25.804Z  \n",
       "0        209730076  2023-12-13T15:26:07.832Z  \n",
       "0        209781912  2023-12-13T15:26:53.278Z  \n",
       "0        209772073  2023-12-13T15:27:35.176Z  \n",
       "0        209781740  2023-12-13T15:28:18.993Z  \n",
       "0        209730193  2023-12-13T15:29:18.477Z  \n",
       "0        160682399  2023-12-13T15:32:23.418Z  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_download_urls():\n",
    "    total_pages = 1\n",
    "    current_page = 0\n",
    "    df_list = []\n",
    "    while current_page < total_pages:\n",
    "        results = requests.get(url=PRODUCT_API_PATH,\n",
    "                                   params={'page': total_pages,\n",
    "                                           'partition_key_after': '2023-05-01',   # optionally set date value here\n",
    "                                           'partition_key_before': '2023-05-31', \n",
    "                                          }, # optionally set date value here\n",
    "                                   headers={'X-API-KEY': API_KEY,\n",
    "                                            'accept': 'application/json'\n",
    "                                           })\n",
    "        response_json = results.json()\n",
    "        total_pages = response_json['total_pages']\n",
    "    \n",
    "        df = pd.DataFrame(response_json)\n",
    "        df_list.append(df)\n",
    "        current_page += 1\n",
    "            \n",
    "    response_df = pd.concat(df_list)\n",
    "    \n",
    "    \n",
    "    df_list2 = []\n",
    "    for idx, row in response_df.iterrows():\n",
    "        # print(row['download_links'])\n",
    "        df = pd.DataFrame.from_dict([row['download_links']])\n",
    "        df_list2.append(df)\n",
    "        # break\n",
    "        \n",
    "    url_df = pd.concat(df_list2).sort_values(\"partition_key\")\n",
    "    return response_df, url_df\n",
    "\n",
    "response_df, url_df = get_all_download_urls()\n",
    "url_df.to_csv(r'D:\\SafeGraph\\Advan_2024_API\\Neighborhood_Patterns\\2023\\05\\01\\Readme.csv', index=False)\n",
    "url_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T20:45:20.543431Z",
     "iopub.status.busy": "2024-01-27T20:45:20.543431Z",
     "iopub.status.idle": "2024-01-27T20:46:24.554720Z",
     "shell.execute_reply": "2024-01-27T20:46:24.553718Z",
     "shell.execute_reply.started": "2024-01-27T20:45:20.543431Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year, month, day: 2023 05 01\n",
      "Downloading file D:\\SafeGraph\\Advan_2024_API\\Neighborhood_Patterns\\2023\\05\\01\\Neighborhood_Patterns_US-DATE_RANGE_START-2023-05-01_1.csv.gz\n",
      "File successfully written.\n",
      "    Downloaded 1 / 10 files for 2023-05-01.\n",
      "Downloaded 1 / 10 files in total.\n",
      "\n",
      "Year, month, day: 2023 05 01\n",
      "Downloading file D:\\SafeGraph\\Advan_2024_API\\Neighborhood_Patterns\\2023\\05\\01\\Neighborhood_Patterns_US-DATE_RANGE_START-2023-05-01_2.csv.gz\n",
      "File successfully written.\n",
      "    Downloaded 2 / 10 files for 2023-05-01.\n",
      "Downloaded 2 / 10 files in total.\n",
      "\n",
      "Year, month, day: 2023 05 01\n",
      "Downloading file D:\\SafeGraph\\Advan_2024_API\\Neighborhood_Patterns\\2023\\05\\01\\Neighborhood_Patterns_US-DATE_RANGE_START-2023-05-01_3.csv.gz\n",
      "File successfully written.\n",
      "    Downloaded 3 / 10 files for 2023-05-01.\n",
      "Downloaded 3 / 10 files in total.\n",
      "\n",
      "Year, month, day: 2023 05 01\n",
      "Downloading file D:\\SafeGraph\\Advan_2024_API\\Neighborhood_Patterns\\2023\\05\\01\\Neighborhood_Patterns_US-DATE_RANGE_START-2023-05-01_4.csv.gz\n",
      "File successfully written.\n",
      "    Downloaded 4 / 10 files for 2023-05-01.\n",
      "Downloaded 4 / 10 files in total.\n",
      "\n",
      "Year, month, day: 2023 05 01\n",
      "Downloading file D:\\SafeGraph\\Advan_2024_API\\Neighborhood_Patterns\\2023\\05\\01\\Neighborhood_Patterns_US-DATE_RANGE_START-2023-05-01_5.csv.gz\n",
      "File successfully written.\n",
      "    Downloaded 5 / 10 files for 2023-05-01.\n",
      "Downloaded 5 / 10 files in total.\n",
      "\n",
      "Year, month, day: 2023 05 01\n",
      "Downloading file D:\\SafeGraph\\Advan_2024_API\\Neighborhood_Patterns\\2023\\05\\01\\Neighborhood_Patterns_US-DATE_RANGE_START-2023-05-01_6.csv.gz\n",
      "File successfully written.\n",
      "    Downloaded 6 / 10 files for 2023-05-01.\n",
      "Downloaded 6 / 10 files in total.\n",
      "\n",
      "Year, month, day: 2023 05 01\n",
      "Downloading file D:\\SafeGraph\\Advan_2024_API\\Neighborhood_Patterns\\2023\\05\\01\\Neighborhood_Patterns_US-DATE_RANGE_START-2023-05-01_7.csv.gz\n",
      "File successfully written.\n",
      "    Downloaded 7 / 10 files for 2023-05-01.\n",
      "Downloaded 7 / 10 files in total.\n",
      "\n",
      "Year, month, day: 2023 05 01\n",
      "Downloading file D:\\SafeGraph\\Advan_2024_API\\Neighborhood_Patterns\\2023\\05\\01\\Neighborhood_Patterns_US-DATE_RANGE_START-2023-05-01_8.csv.gz\n",
      "File successfully written.\n",
      "    Downloaded 8 / 10 files for 2023-05-01.\n",
      "Downloaded 8 / 10 files in total.\n",
      "\n",
      "Year, month, day: 2023 05 01\n",
      "Downloading file D:\\SafeGraph\\Advan_2024_API\\Neighborhood_Patterns\\2023\\05\\01\\Neighborhood_Patterns_US-DATE_RANGE_START-2023-05-01_9.csv.gz\n",
      "File successfully written.\n",
      "    Downloaded 9 / 10 files for 2023-05-01.\n",
      "Downloaded 9 / 10 files in total.\n",
      "\n",
      "Year, month, day: 2023 05 01\n",
      "Downloading file D:\\SafeGraph\\Advan_2024_API\\Neighborhood_Patterns\\2023\\05\\01\\Neighborhood_Patterns_US-DATE_RANGE_START-2023-05-01_10.csv.gz\n",
      "File successfully written.\n",
      "    Downloaded 10 / 10 files for 2023-05-01.\n",
      "Downloaded 10 / 10 files in total.\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "downloaded_cnt = 0\n",
    "\n",
    "def formart_file_name(row, index):\n",
    "    # remove file number in the middle\n",
    "    file_name = row['file_name']\n",
    "    file_extension = row['file_extension']\n",
    "    hypen_pos_list = [p for p, char in enumerate(file_name) if char == '-']\n",
    "    hyphen_pos1 = hypen_pos_list[0]\n",
    "    hyphen_pos2 = hypen_pos_list[1]\n",
    "    new_fname = file_name[:hyphen_pos1] + file_name[hyphen_pos2:]\n",
    "    new_fname = new_fname[:-len(file_extension)] + f'{index:02}' + file_extension\n",
    "    return new_fname \n",
    "    \n",
    "for partition_key, df in url_df.groupby('partition_key'):\n",
    "   \n",
    "    df = df.reset_index()\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            # print(partition_key, i + 1)\n",
    "            # print(\"Downloading: \", row['link'])\n",
    "            date = row['partition_key']\n",
    "            file_extension = row['file_extension']\n",
    "            year = date[:4]\n",
    "            month = date[5:7]\n",
    "            day = date[-2:]\n",
    "            file_dir = os.path.join(save_dir, year, month, day)\n",
    "            os.makedirs(file_dir, exist_ok=True)\n",
    "            print(\"Year, month, day:\", year, month, day)\n",
    "    \n",
    "            # base_name = row['file_name']\n",
    "            base_name = row['file_name'][0:24] + row['file_name'][-35:-7] + f\"_{i + 1}.csv.gz\"\n",
    "            # base_name = formart_file_name(row, i)\n",
    "            # print(\"base_name:\", base_name)\n",
    "            \n",
    "            file_name = os.path.join(file_dir, base_name)\n",
    "             \n",
    "            print(f'Downloading file {file_name}')\n",
    "        \n",
    "            if os.path.exists(file_name):\n",
    "                print(f\"File exists, skip! The file is: {file_name} \\n\")\n",
    "                continue\n",
    "        \n",
    "            # # loop through download links and save to your computer\n",
    "            data = requests.get(row['link'], stream=True)\n",
    "            safe_file_write(file_path=file_name, content=data.content)\n",
    "             \n",
    "            #  += 1\n",
    "            downloaded_cnt += 1\n",
    "            print(f\"    Downloaded {i + 1} / {len(df)} files for {partition_key}.\")\n",
    "            print(f\"Downloaded {downloaded_cnt} / {len(url_df)} files in total.\")\n",
    "            # print(f\"Downloaded {download_count} files in total, Page {page} / {total_pages}.\")\n",
    "            \n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            continue\n",
    "\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T20:33:48.171551Z",
     "iopub.status.busy": "2024-01-27T20:33:48.171551Z",
     "iopub.status.idle": "2024-01-27T20:33:48.228819Z",
     "shell.execute_reply": "2024-01-27T20:33:48.227817Z",
     "shell.execute_reply.started": "2024-01-27T20:33:48.171551Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3876836952.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[57], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Not used below\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Not used below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T20:39:21.298603Z",
     "iopub.status.busy": "2024-01-27T20:39:21.298603Z",
     "iopub.status.idle": "2024-01-27T20:39:21.361015Z",
     "shell.execute_reply": "2024-01-27T20:39:21.360014Z",
     "shell.execute_reply.started": "2024-01-27T20:39:21.298603Z"
    }
   },
   "outputs": [],
   "source": [
    "# downloaded_cnt = 0\n",
    "# for partition_key, df in url_df.groupby('partition_key'):\n",
    "   \n",
    "#     df = df.reset_index()\n",
    "#     for i, row in df.iterrows():\n",
    "#         try:\n",
    "#             # print(partition_key, i + 1)\n",
    "#             # print(\"Downloading: \", row['link'])\n",
    "#             date = row['partition_key']\n",
    "#             year = date[:4]\n",
    "#             month = date[5:7]\n",
    "#             day = date[-2:]\n",
    "#             file_dir = os.path.join(save_dir, year, month, day)\n",
    "#             os.makedirs(file_dir, exist_ok=True)\n",
    "#             print(\"Year, month, day:\", year, month, day)\n",
    "    \n",
    "#             # base_name = row['file_name']\n",
    "#             base_name = row['file_name'][0:24] + row['file_name'][-35:-7] + f\"_{i + 1:02}.csv.gz\"\n",
    "#             # print(\"base_name:\", base_name)\n",
    "            \n",
    "#             file_name = os.path.join(file_dir, base_name)\n",
    "             \n",
    "#             print(f'Downloading file {file_name}')\n",
    "        \n",
    "#             if os.path.exists(file_name):\n",
    "#                 print(f\"File exists, skip! The file is: {file_name} \\n\")\n",
    "#                 continue\n",
    "        \n",
    "#             # # loop through download links and save to your computer\n",
    "#             data = requests.get(row['link'], stream=True)\n",
    "#             safe_file_write(file_path=file_name, content=data.content)\n",
    "             \n",
    "#             #  += 1\n",
    "#             downloaded_cnt += 1\n",
    "#             print(f\"    Downloaded {i + 1} / {len(df)} files for {partition_key}.\")\n",
    "#             print(f\"Downloaded {downloaded_cnt} / {len(url_df)} files in total.\")\n",
    "#             # print(f\"Downloaded {download_count} files in total, Page {page} / {total_pages}.\")\n",
    "            \n",
    "#             print()\n",
    "#         except Exception as e:\n",
    "#             print(\"Error:\", e)\n",
    "#             continue\n",
    "\n",
    "# print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP\n",
    "\n",
    "Not used below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## api_key = r'J923tlBL.54vRQ2rAhcMc8nhb1v6IZyJwCWUkgG2LA33tHCpJJXhFwilrUhT1ckxJ'\n",
    "\n",
    " \n",
    "# neighborhood patterns:\n",
    "url = r'https://app.deweydata.io/external-api/v3/products/2dfcb598-6e30-49f1-bdba-1deae113a951/files'\n",
    "# save_dir = r'K:\\SafeGraph\\Advan_2023_API\\Neighborhood_Patterns'   # Dell 2019\n",
    "save_dir = r'F:\\SafeGraph\\Advan_2023_API\\Neighborhood_Patterns'  # Lenova 2018\n",
    "\n",
    "# monthly patterns:\n",
    "# url = r\"https://app.deweydata.io/external-api/v3/products/5acc9f39-1ca6-4535-b3ff-38f6b9baf85e/files\"\n",
    "# save_dir = r'K:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns'\n",
    "\n",
    "# # weekly patterns:\n",
    "# url = r\"https://app.deweydata.io/external-api/v3/products/176f0262-c1f6-4dbe-be43-6a6eb21bcf8a/files\"\n",
    "# save_dir = r'K:\\SafeGraph\\Advan_2023_API\\Weekly_Patterns'\n",
    "\n",
    "# # hourly weather:\n",
    "# url = r\"https://app.deweydata.io/external-api/v3/products/a6be0385-8820-4943-a509-6eac4154b4f6/files\"\n",
    "\n",
    "# monthly home panel summary\n",
    "# url = r'https://app.deweydata.io/external-api/v3/products/8546740c-b0e9-4556-abb9-4bea2cca9ac9/files'\n",
    "# save_dir = r'F:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary'\n",
    "\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "# set key and API endpoint variables\n",
    "API_KEY = access_token\n",
    "PRODUCT_API_PATH = url\n",
    "\n",
    "# loop through all API result pages, keeping track of number of downloaded files\n",
    "page = 1\n",
    "download_count = 0\n",
    "\n",
    "while True:\n",
    "    # get results from API endpoint, using API key for authentication\n",
    "    results = requests.get(url=PRODUCT_API_PATH,\n",
    "                           params={'page': page,\n",
    "                                   'partition_key_after': '2018-01-01',   # optionally set date value here\n",
    "                                   'partition_key_before': '2023-12-31', \n",
    "                                  }, # optionally set date value here\n",
    "                           headers={'X-API-KEY': API_KEY,\n",
    "                                    'accept': 'application/json'\n",
    "                                   })\n",
    "    response_json = results.json()\n",
    "    total_pages = response_json['total_pages']\n",
    "\n",
    "    link_cnt = len(response_json['download_links'])\n",
    " \n",
    "    # for each result page, loop through download links and save to your computer\n",
    "    for idx, link_data in enumerate(response_json['download_links']):\n",
    "        # create file name for each link\n",
    "        print(f\"Downloading {idx + 1} / {link_cnt} files, in Page {page}.\")\n",
    "        print(f\"Downloading {download_count} files in total, Page {page} / {total_pages}.\")\n",
    "        \n",
    "        if response_json['partition_column']:\n",
    "            date = link_data['partition_key']\n",
    "            year = date[:4]\n",
    "            month = date[5:7]\n",
    "            day = date[-2:]\n",
    "            file_dir = os.path.join(save_dir, year, month, day)\n",
    "            os.makedirs(file_dir, exist_ok=True)\n",
    "            print(\"Year, month, day:\", year, month, day)\n",
    "            # file_name = f\"file-{download_count+1}-{response_json['partition_column']}-{link_data['partition_key']}.csv.gz\" \n",
    "            # url = link_data['link']\n",
    "            # parsed_url = urlparse(url)\n",
    "            # path = parsed_url.path\n",
    "            # base_name = os.path.basename(path)\n",
    "            # base_name = unquote(base_name) \n",
    "            base_name = link_data['file_name']\n",
    "            base_name = base_name[0:24] + base_name[-35:] \n",
    "            \n",
    "            file_name = os.path.join(file_dir, base_name)\n",
    "            \n",
    "        else:\n",
    "            # not tested\n",
    "            # url = link_data['link']\n",
    "            # parsed_url = urlparse(url)\n",
    "            # path = parsed_url.path\n",
    "            # base_name = os.path.basename(path)\n",
    "            # base_name = unquote(base_name) \n",
    "            base_name = link_data['file_name']  \n",
    "            # need to remove the numbers in the result: Neighborhood_Patterns_US-8-DATE_RANGE_START-2020-02-01.csv # 2024-01-05\n",
    "            base_name = base_name[0:24] + base_name[-35:] \n",
    "            # print(\"base_name:\", base_name)\n",
    "            \n",
    "            file_name = os.path.join(file_dir, base_name)\n",
    "            \n",
    "        print(f'Downloading file {file_name}')\n",
    "\n",
    "        if os.path.exists(file_name):\n",
    "            print(f\"File exists, skip! The file is: {file_name} \\n\")\n",
    "            continue\n",
    "\n",
    "        # # loop through download links and save to your computer\n",
    "        data = requests.get(link_data['link'], stream=True)\n",
    "        safe_file_write(file_path=file_name, content=data.content)\n",
    "        \n",
    "  \n",
    "        download_count += 1\n",
    "        print(f\"Downloaded {idx + 1} / {link_cnt} files, in Page {page}.\")\n",
    "        print(f\"Downloaded {download_count} files in total, Page {page} / {total_pages}.\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "    # only continue if there are more result pages to process    \n",
    "    if page >= total_pages:\n",
    "        break\n",
    "        \n",
    "    page += 1\n",
    "    \n",
    "    \n",
    "\n",
    "print(f\"Successfully downloaded {download_count} files.\")\n",
    "\n",
    "print(\"Done\")\n",
    "# returns = results.json()\n",
    "# print(returns.keys())\n",
    "# print(len(returns['download_links']))\n",
    "# del returns['download_links']\n",
    "# returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download monthly patterns home panel summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T19:37:14.366910Z",
     "iopub.status.busy": "2024-01-27T19:37:14.365880Z",
     "iopub.status.idle": "2024-01-27T19:37:51.254201Z",
     "shell.execute_reply": "2024-01-27T19:37:51.253201Z",
     "shell.execute_reply.started": "2024-01-27T19:37:14.366910Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1 / 60 files, in Page 1.\n",
      "Downloading 0 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-0.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 1 / 60 files, in Page 1.\n",
      "Downloaded 1 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 2 / 60 files, in Page 1.\n",
      "Downloading 1 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-1.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 2 / 60 files, in Page 1.\n",
      "Downloaded 2 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 3 / 60 files, in Page 1.\n",
      "Downloading 2 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-2.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 3 / 60 files, in Page 1.\n",
      "Downloaded 3 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 4 / 60 files, in Page 1.\n",
      "Downloading 3 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-3.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 4 / 60 files, in Page 1.\n",
      "Downloaded 4 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 5 / 60 files, in Page 1.\n",
      "Downloading 4 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-4.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 5 / 60 files, in Page 1.\n",
      "Downloaded 5 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 6 / 60 files, in Page 1.\n",
      "Downloading 5 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-5.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 6 / 60 files, in Page 1.\n",
      "Downloaded 6 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 7 / 60 files, in Page 1.\n",
      "Downloading 6 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-6.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 7 / 60 files, in Page 1.\n",
      "Downloaded 7 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 8 / 60 files, in Page 1.\n",
      "Downloading 7 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-7.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 8 / 60 files, in Page 1.\n",
      "Downloaded 8 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 9 / 60 files, in Page 1.\n",
      "Downloading 8 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-8.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 9 / 60 files, in Page 1.\n",
      "Downloaded 9 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 10 / 60 files, in Page 1.\n",
      "Downloading 9 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-9.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 10 / 60 files, in Page 1.\n",
      "Downloaded 10 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 11 / 60 files, in Page 1.\n",
      "Downloading 10 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-10.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 11 / 60 files, in Page 1.\n",
      "Downloaded 11 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 12 / 60 files, in Page 1.\n",
      "Downloading 11 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-11.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 12 / 60 files, in Page 1.\n",
      "Downloaded 12 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 13 / 60 files, in Page 1.\n",
      "Downloading 12 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-12.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 13 / 60 files, in Page 1.\n",
      "Downloaded 13 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 14 / 60 files, in Page 1.\n",
      "Downloading 13 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-13.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 14 / 60 files, in Page 1.\n",
      "Downloaded 14 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 15 / 60 files, in Page 1.\n",
      "Downloading 14 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-14.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 15 / 60 files, in Page 1.\n",
      "Downloaded 15 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 16 / 60 files, in Page 1.\n",
      "Downloading 15 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-15.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 16 / 60 files, in Page 1.\n",
      "Downloaded 16 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 17 / 60 files, in Page 1.\n",
      "Downloading 16 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-16.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 17 / 60 files, in Page 1.\n",
      "Downloaded 17 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 18 / 60 files, in Page 1.\n",
      "Downloading 17 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-17.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 18 / 60 files, in Page 1.\n",
      "Downloaded 18 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 19 / 60 files, in Page 1.\n",
      "Downloading 18 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-18.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 19 / 60 files, in Page 1.\n",
      "Downloaded 19 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 20 / 60 files, in Page 1.\n",
      "Downloading 19 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-19.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 20 / 60 files, in Page 1.\n",
      "Downloaded 20 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 21 / 60 files, in Page 1.\n",
      "Downloading 20 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-20.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 21 / 60 files, in Page 1.\n",
      "Downloaded 21 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 22 / 60 files, in Page 1.\n",
      "Downloading 21 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-21.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 22 / 60 files, in Page 1.\n",
      "Downloaded 22 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 23 / 60 files, in Page 1.\n",
      "Downloading 22 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-22.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 23 / 60 files, in Page 1.\n",
      "Downloaded 23 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 24 / 60 files, in Page 1.\n",
      "Downloading 23 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-23.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 24 / 60 files, in Page 1.\n",
      "Downloaded 24 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 25 / 60 files, in Page 1.\n",
      "Downloading 24 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-24.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 25 / 60 files, in Page 1.\n",
      "Downloaded 25 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 26 / 60 files, in Page 1.\n",
      "Downloading 25 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-25.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 26 / 60 files, in Page 1.\n",
      "Downloaded 26 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 27 / 60 files, in Page 1.\n",
      "Downloading 26 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-26.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 27 / 60 files, in Page 1.\n",
      "Downloaded 27 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 28 / 60 files, in Page 1.\n",
      "Downloading 27 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-27.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 28 / 60 files, in Page 1.\n",
      "Downloaded 28 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 29 / 60 files, in Page 1.\n",
      "Downloading 28 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-28.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 29 / 60 files, in Page 1.\n",
      "Downloaded 29 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 30 / 60 files, in Page 1.\n",
      "Downloading 29 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-29.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 30 / 60 files, in Page 1.\n",
      "Downloaded 30 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 31 / 60 files, in Page 1.\n",
      "Downloading 30 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-30.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 31 / 60 files, in Page 1.\n",
      "Downloaded 31 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 32 / 60 files, in Page 1.\n",
      "Downloading 31 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-31.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 32 / 60 files, in Page 1.\n",
      "Downloaded 32 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 33 / 60 files, in Page 1.\n",
      "Downloading 32 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-32.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 33 / 60 files, in Page 1.\n",
      "Downloaded 33 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 34 / 60 files, in Page 1.\n",
      "Downloading 33 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-33.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 34 / 60 files, in Page 1.\n",
      "Downloaded 34 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 35 / 60 files, in Page 1.\n",
      "Downloading 34 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-34.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 35 / 60 files, in Page 1.\n",
      "Downloaded 35 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 36 / 60 files, in Page 1.\n",
      "Downloading 35 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-35.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 36 / 60 files, in Page 1.\n",
      "Downloaded 36 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 37 / 60 files, in Page 1.\n",
      "Downloading 36 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-36.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 37 / 60 files, in Page 1.\n",
      "Downloaded 37 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 38 / 60 files, in Page 1.\n",
      "Downloading 37 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-37.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 38 / 60 files, in Page 1.\n",
      "Downloaded 38 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 39 / 60 files, in Page 1.\n",
      "Downloading 38 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-38.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 39 / 60 files, in Page 1.\n",
      "Downloaded 39 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 40 / 60 files, in Page 1.\n",
      "Downloading 39 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-39.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 40 / 60 files, in Page 1.\n",
      "Downloaded 40 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 41 / 60 files, in Page 1.\n",
      "Downloading 40 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-40.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 41 / 60 files, in Page 1.\n",
      "Downloaded 41 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 42 / 60 files, in Page 1.\n",
      "Downloading 41 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-41.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 42 / 60 files, in Page 1.\n",
      "Downloaded 42 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 43 / 60 files, in Page 1.\n",
      "Downloading 42 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-42.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 43 / 60 files, in Page 1.\n",
      "Downloaded 43 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 44 / 60 files, in Page 1.\n",
      "Downloading 43 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-43.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 44 / 60 files, in Page 1.\n",
      "Downloaded 44 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 45 / 60 files, in Page 1.\n",
      "Downloading 44 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-44.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 45 / 60 files, in Page 1.\n",
      "Downloaded 45 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 46 / 60 files, in Page 1.\n",
      "Downloading 45 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-45.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 46 / 60 files, in Page 1.\n",
      "Downloaded 46 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 47 / 60 files, in Page 1.\n",
      "Downloading 46 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-46.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 47 / 60 files, in Page 1.\n",
      "Downloaded 47 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 48 / 60 files, in Page 1.\n",
      "Downloading 47 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-47.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 48 / 60 files, in Page 1.\n",
      "Downloaded 48 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 49 / 60 files, in Page 1.\n",
      "Downloading 48 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-48.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 49 / 60 files, in Page 1.\n",
      "Downloaded 49 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 50 / 60 files, in Page 1.\n",
      "Downloading 49 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-49.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 50 / 60 files, in Page 1.\n",
      "Downloaded 50 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 51 / 60 files, in Page 1.\n",
      "Downloading 50 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-50.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 51 / 60 files, in Page 1.\n",
      "Downloaded 51 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 52 / 60 files, in Page 1.\n",
      "Downloading 51 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-51.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 52 / 60 files, in Page 1.\n",
      "Downloaded 52 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 53 / 60 files, in Page 1.\n",
      "Downloading 52 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-52.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 53 / 60 files, in Page 1.\n",
      "Downloaded 53 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 54 / 60 files, in Page 1.\n",
      "Downloading 53 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-53.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 54 / 60 files, in Page 1.\n",
      "Downloaded 54 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 55 / 60 files, in Page 1.\n",
      "Downloading 54 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-54.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 55 / 60 files, in Page 1.\n",
      "Downloaded 55 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 56 / 60 files, in Page 1.\n",
      "Downloading 55 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-55.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 56 / 60 files, in Page 1.\n",
      "Downloaded 56 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 57 / 60 files, in Page 1.\n",
      "Downloading 56 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-56.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 57 / 60 files, in Page 1.\n",
      "Downloaded 57 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 58 / 60 files, in Page 1.\n",
      "Downloading 57 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-57.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 58 / 60 files, in Page 1.\n",
      "Downloaded 58 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 59 / 60 files, in Page 1.\n",
      "Downloading 58 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-58.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 59 / 60 files, in Page 1.\n",
      "Downloaded 59 files in total, Page 1 / 1.\n",
      "\n",
      "Downloading 60 / 60 files, in Page 1.\n",
      "Downloading 59 files in total, Page 1 / 1.\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_Home_Panel_Summary-59.csv.gz\n",
      "File successfully written.\n",
      "Downloaded 60 / 60 files, in Page 1.\n",
      "Downloaded 60 files in total, Page 1 / 1.\n",
      "\n",
      "Successfully downloaded 60 files.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "api_key = r'J923tlBL.54vRQ2rAhcMc8nhb1v6IZyJwCWUkgG2LA33tHCpJJXhFwilrUhT1ckxJ'\n",
    "\n",
    "# monthly home panel summary\n",
    "url = r'https://app.deweydata.io/external-api/v3/products/8546740c-b0e9-4556-abb9-4bea2cca9ac9/files'\n",
    "save_dir = r'D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# set key and API endpoint variables\n",
    "API_KEY = access_token\n",
    "PRODUCT_API_PATH = url\n",
    "\n",
    "# loop through all API result pages, keeping track of number of downloaded files\n",
    "page = 1\n",
    "download_count = 0\n",
    "\n",
    "while True:\n",
    "    # get results from API endpoint, using API key for authentication\n",
    "    results = requests.get(url=PRODUCT_API_PATH,\n",
    "                           params={'page': page,\n",
    "                                   # 'partition_key_after': '2023-05-30',   # optionally set date value here\n",
    "                                   # 'partition_key_before': '2023-09-01', \n",
    "                                  }, # optionally set date value here\n",
    "                           headers={'X-API-KEY': API_KEY,\n",
    "                                    'accept': 'application/json'\n",
    "                                   })\n",
    "    response_json = results.json()\n",
    "    total_pages = response_json['total_pages']\n",
    "\n",
    "    link_cnt = len(response_json['download_links'])\n",
    "     \n",
    "    # for each result page, loop through download links and save to your computer\n",
    "    for idx, link_data in enumerate(response_json['download_links']):\n",
    "        # create file name for each link\n",
    "        print(f\"Downloading {idx + 1} / {link_cnt} files, in Page {page}.\")\n",
    "        print(f\"Downloading {download_count} files in total, Page {page} / {total_pages}.\")\n",
    "        \n",
    "        if response_json['partition_column']:\n",
    "            date = link_data['partition_key']\n",
    "            # year = date[:4]\n",
    "            # month = date[5:7]\n",
    "            # day = date[-2:]\n",
    "     \n",
    "            \n",
    "            # print(\"Year, month, day:\", year, month, day)\n",
    "            # file_name = f\"file-{download_count+1}-{response_json['partition_column']}-{link_data['partition_key']}.csv.gz\" \n",
    "            # url = link_data['link']\n",
    "            # parsed_url = urlparse(url)\n",
    "            # path = parsed_url.path\n",
    "            # base_name = os.path.basename(path)\n",
    "            base_name = link_data['file_name']\n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # not tested\n",
    "            url = link_data['link']\n",
    "            # parsed_url = urlparse(url)\n",
    "            # path = parsed_url.path\n",
    "            base_name = link_data['file_name']\n",
    "            file_name = os.path.join(save_dir, base_name)\n",
    "            \n",
    "            \n",
    "        print(f'Downloading file {file_name}')\n",
    "\n",
    "        if os.path.exists(file_name):\n",
    "            print(f\"File exists, skip! The file is: {file_name} \\n\")\n",
    "            continue\n",
    "\n",
    "        # # loop through download links and save to your computer\n",
    "        data = requests.get(link_data['link'], stream=True)\n",
    "        safe_file_write(file_path=file_name, content=data.content)\n",
    "        \n",
    "        \n",
    "        # with open(file_name, 'wb') as file:            \n",
    "        #     file.write(data.content)\n",
    "             \n",
    "        download_count += 1\n",
    "        print(f\"Downloaded {idx + 1} / {link_cnt} files, in Page {page}.\")\n",
    "        print(f\"Downloaded {download_count} files in total, Page {page} / {total_pages}.\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "    # only continue if there are more result pages to process\n",
    "    \n",
    "    if page >= total_pages:\n",
    "        break\n",
    "        \n",
    "    page += 1\n",
    "    \n",
    "    \n",
    "\n",
    "print(f\"Successfully downloaded {download_count} files.\")\n",
    "\n",
    "print(\"Done\")\n",
    "# returns = results.json()\n",
    "# print(returns.keys())\n",
    "# print(len(returns['download_links']))\n",
    "# del returns['download_links']\n",
    "# returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge monthly patterns home panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T19:37:53.886249Z",
     "iopub.status.busy": "2024-01-27T19:37:53.886249Z",
     "iopub.status.idle": "2024-01-27T19:37:53.944494Z",
     "shell.execute_reply": "2024-01-27T19:37:53.943493Z",
     "shell.execute_reply.started": "2024-01-27T19:37:53.886249Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = r'D:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T19:37:55.370269Z",
     "iopub.status.busy": "2024-01-27T19:37:55.370269Z",
     "iopub.status.idle": "2024-01-27T19:38:08.004774Z",
     "shell.execute_reply": "2024-01-27T19:38:08.004774Z",
     "shell.execute_reply.started": "2024-01-27T19:37:55.370269Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MON</th>\n",
       "      <th>REGION</th>\n",
       "      <th>ISO_COUNTRY_CODE</th>\n",
       "      <th>CENSUS_BLOCK_GROUP</th>\n",
       "      <th>NUMBER_DEVICES_RESIDING</th>\n",
       "      <th>NUMBER_DEVICES_PRIMARY_DAYTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>AB</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA:48061115</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>AB</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA:48100361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>AB</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA:48111082</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>AB</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA:48111712</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>AB</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA:48111787</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268692</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>YT</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA:60010269</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268693</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>YT</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA:60010223</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268694</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>YT</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA:60010282</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268695</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>YT</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA:60010252</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268696</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>YT</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA:60010228</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16194438 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        YEAR  MON REGION ISO_COUNTRY_CODE CENSUS_BLOCK_GROUP  \\\n",
       "0       2020    9     AB               CA        CA:48061115   \n",
       "1       2020    9     AB               CA        CA:48100361   \n",
       "2       2020    9     AB               CA        CA:48111082   \n",
       "3       2020    9     AB               CA        CA:48111712   \n",
       "4       2020    9     AB               CA        CA:48111787   \n",
       "...      ...  ...    ...              ...                ...   \n",
       "268692  2021    9     YT               CA        CA:60010269   \n",
       "268693  2021    9     YT               CA        CA:60010223   \n",
       "268694  2021    9     YT               CA        CA:60010282   \n",
       "268695  2021    9     YT               CA        CA:60010252   \n",
       "268696  2021    9     YT               CA        CA:60010228   \n",
       "\n",
       "        NUMBER_DEVICES_RESIDING  NUMBER_DEVICES_PRIMARY_DAYTIME  \n",
       "0                           9.0                             NaN  \n",
       "1                           1.0                             NaN  \n",
       "2                           5.0                             NaN  \n",
       "3                           5.0                             NaN  \n",
       "4                           2.0                             NaN  \n",
       "...                         ...                             ...  \n",
       "268692                     14.0                             5.0  \n",
       "268693                     18.0                             7.0  \n",
       "268694                     18.0                             7.0  \n",
       "268695                     14.0                             7.0  \n",
       "268696                     22.0                            10.0  \n",
       "\n",
       "[16194438 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel_df = ad_op.load_neighborhood_monthly_folder(folder,  extions=['gz'], start_str='Monthly_Patterns_Home_Panel_Summary', use_cols=None, verbose=True, test=False)\n",
    "panel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T20:23:19.855456Z",
     "iopub.status.busy": "2024-01-27T20:23:19.854457Z",
     "iopub.status.idle": "2024-01-27T20:25:15.173696Z",
     "shell.execute_reply": "2024-01-27T20:25:15.173696Z",
     "shell.execute_reply.started": "2024-01-27T20:23:19.855456Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_fname = r'E:\\OneDrive_PSU\\OneDrive - The Pennsylvania State University\\Research_doc\\Wild_fire\\home_panel_summary_2019_2023_restated_20240119.csv.gz'\n",
    "panel_df.to_csv(new_fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T19:42:08.685152Z",
     "iopub.status.busy": "2024-01-27T19:42:08.685152Z",
     "iopub.status.idle": "2024-01-27T19:42:09.744018Z",
     "shell.execute_reply": "2024-01-27T19:42:09.744018Z",
     "shell.execute_reply.started": "2024-01-27T19:42:08.685152Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181750.54166666666"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(panel_df.query(f\"ISO_COUNTRY_CODE == 'US' \")) / 6 / 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T19:42:41.818325Z",
     "iopub.status.busy": "2024-01-27T19:42:41.818325Z",
     "iopub.status.idle": "2024-01-27T19:42:43.506298Z",
     "shell.execute_reply": "2024-01-27T19:42:43.505327Z",
     "shell.execute_reply.started": "2024-01-27T19:42:41.818325Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monthly_device_cnt_df   (million):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MON</th>\n",
       "      <th>NUMBER_DEVICES_RESIDING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>66.145175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>62.823365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>66.860446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>40.499184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>41.970806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>41.172800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>35.953265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>29.020312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>29.037359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>28.627546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>26.625356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>26.372042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>24.715253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>24.189729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>24.134373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>22.267798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>22.218687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>22.700255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>22.581346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>23.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>23.189349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>22.952380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>22.300225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>21.233045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>20.569747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>19.709469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>18.968102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>17.255287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>18.279663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>17.843876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>17.241893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>17.446045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>17.090689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>17.006155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>16.839845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>16.810387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>16.496158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>16.365649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>20.871826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>21.104201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>21.414853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>27.065404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>23.421824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>23.703003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>23.944498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>23.582564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>23.541959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>23.823517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>39.603850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>13.172336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>14.402220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>15.104544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>15.071957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "      <td>17.164313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "      <td>17.736300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>18.170850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>15.949760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>14.554956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>13.205879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>13.545774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR  MON  NUMBER_DEVICES_RESIDING\n",
       "0   2019    1                66.145175\n",
       "1   2019    2                62.823365\n",
       "2   2019    3                66.860446\n",
       "3   2019    4                40.499184\n",
       "4   2019    5                41.970806\n",
       "5   2019    6                41.172800\n",
       "6   2019    7                35.953265\n",
       "7   2019    8                29.020312\n",
       "8   2019    9                29.037359\n",
       "9   2019   10                28.627546\n",
       "10  2019   11                26.625356\n",
       "11  2019   12                26.372042\n",
       "12  2020    1                24.715253\n",
       "13  2020    2                24.189729\n",
       "14  2020    3                24.134373\n",
       "15  2020    4                22.267798\n",
       "16  2020    5                22.218687\n",
       "17  2020    6                22.700255\n",
       "18  2020    7                22.581346\n",
       "19  2020    8                23.628205\n",
       "20  2020    9                23.189349\n",
       "21  2020   10                22.952380\n",
       "22  2020   11                22.300225\n",
       "23  2020   12                21.233045\n",
       "24  2021    1                20.569747\n",
       "25  2021    2                19.709469\n",
       "26  2021    3                18.968102\n",
       "27  2021    4                17.255287\n",
       "28  2021    5                18.279663\n",
       "29  2021    6                17.843876\n",
       "30  2021    7                17.241893\n",
       "31  2021    8                17.446045\n",
       "32  2021    9                17.090689\n",
       "33  2021   10                17.006155\n",
       "34  2021   11                16.839845\n",
       "35  2021   12                16.810387\n",
       "36  2022    1                16.496158\n",
       "37  2022    2                16.365649\n",
       "38  2022    3                20.871826\n",
       "39  2022    4                21.104201\n",
       "40  2022    5                21.414853\n",
       "41  2022    6                27.065404\n",
       "42  2022    7                23.421824\n",
       "43  2022    8                23.703003\n",
       "44  2022    9                23.944498\n",
       "45  2022   10                23.582564\n",
       "46  2022   11                23.541959\n",
       "47  2022   12                23.823517\n",
       "48  2023    1                39.603850\n",
       "49  2023    2                13.172336\n",
       "50  2023    3                14.402220\n",
       "51  2023    4                15.104544\n",
       "52  2023    5                15.071957\n",
       "53  2023    6                17.164313\n",
       "54  2023    7                17.736300\n",
       "55  2023    8                18.170850\n",
       "56  2023    9                15.949760\n",
       "57  2023   10                14.554956\n",
       "58  2023   11                13.205879\n",
       "59  2023   12                13.545774"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_device_cnt_df = panel_df.query(f\"ISO_COUNTRY_CODE == 'US' \").groupby(['YEAR', 'MON'], as_index=True)['NUMBER_DEVICES_RESIDING'].sum() / 10**6\n",
    "print(\"monthly_device_cnt_df   (million):\" )\n",
    "monthly_device_cnt_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-27T20:21:58.084412Z",
     "iopub.status.busy": "2024-01-27T20:21:58.083384Z",
     "iopub.status.idle": "2024-01-27T20:21:58.147876Z",
     "shell.execute_reply": "2024-01-27T20:21:58.146906Z",
     "shell.execute_reply.started": "2024-01-27T20:21:58.084412Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not used below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "# from posixpath import basename\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import tempfile\n",
    "\n",
    "def get_access_token(account=\"hning@email.sc.edu\", password=\"Nhwwdewey2022,\", verbose=True):\n",
    "    # un =  # Set username\n",
    "    # pw = # Set password\n",
    "\n",
    "    credentials = f\"{account}:{password}\" # Format credentials according to the API's expectations\n",
    "    # print(credentials)\n",
    "\n",
    "    credentials_bytes = credentials.encode('ascii')\n",
    "    base64_credentials_bytes = base64.b64encode(credentials_bytes)\n",
    "    base64_credentials = base64_credentials_bytes.decode('ascii')\n",
    "    # print(base64_credentials)\n",
    "\n",
    "\n",
    "    headers = {\n",
    "        'accept': 'application/json',\n",
    "        'Authorization': f'Basic {base64_credentials}'\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://marketplace.deweydata.io/api/auth/tks/get_token\", headers=headers)\n",
    "    \n",
    "    access_token = response.json()['access_token']\n",
    "    \n",
    "    if verbose:\n",
    "        print(response.json())\n",
    "        print(access_token)\n",
    "    \n",
    "    return access_token\n",
    "\n",
    "def safe_file_write(file_path, content):\n",
    "    # Create a temporary file in the same directory as the target file\n",
    "    dir_name = os.path.dirname(file_path)\n",
    "    with tempfile.NamedTemporaryFile(mode='wb', dir=dir_name, delete=False) as temp_file:\n",
    "        try:\n",
    "            # Write the content to the temporary file\n",
    "            temp_file.write(content)\n",
    "            temp_file.flush()\n",
    "            os.fsync(temp_file.fileno())\n",
    "            temp_file.close()\n",
    "\n",
    "            # Rename the temporary file to the target file (atomic operation)\n",
    "            os.replace(temp_file.name, file_path)\n",
    "        except Exception as e:\n",
    "            # Handle the exception (e.g., log it, raise it, or silently ignore it)\n",
    "            print(f\"An error occurred while writing the file: {e}\")\n",
    "            os.unlink(temp_file.name)\n",
    "        else:\n",
    "            print(\"File successfully written.\")\n",
    "            \n",
    "            \n",
    "# Main function\n",
    "def download_all_files(save_dir, headers, override=False):\n",
    " \n",
    "    init_url = r'/api/data/v2/list'\n",
    "    home_url = 'https://marketplace.deweydata.io'    \n",
    "    web_dir_list = [init_url]\n",
    "    \n",
    "    print(\"Started...\")\n",
    "    \n",
    "    skipped_cnt = 0\n",
    "    while len(web_dir_list) > 0:\n",
    "        try:\n",
    "            # web_dir = web_dir_list.pop()\n",
    "            # print(\"web_dir_list:\", web_dir_list)\n",
    "            web_dir = web_dir_list.pop()   # Get the latest file\n",
    "            \n",
    "            \n",
    "            url = home_url + web_dir\n",
    "            # print(url, web_dir)\n",
    "            items = requests.get(url, headers=headers).json()\n",
    "            # print(requests.get(url, headers=headers).url)\n",
    "            \n",
    "            items = items[::-1]  # Put the latest file in the end.\n",
    " \n",
    "\n",
    "            for item in items:\n",
    "                name = item['name']\n",
    "                if item['directory']:  \n",
    "                    \n",
    "                    # skip data\n",
    "                    # if r'/2021/' not in url:\n",
    "                    #     # print(\"Skipped:\", url)\n",
    "                    #     skipped_cnt += 1\n",
    "                    #     if skipped_cnt % 10 == 0:\n",
    "                    #         print(\"skipped un-targeted files:\", skipped_cnt)\n",
    "                    #     continue\n",
    "                    \n",
    "                    web_dir = item['url']\n",
    "                    \n",
    "                    full_web_dir = home_url + web_dir\n",
    "\n",
    "                    local_dir = item['parent'].replace(init_url, '').replace(r'/', '\\\\')[1:] # for windows  \n",
    "                                        \n",
    "\n",
    "                    web_dir_list.append(web_dir)\n",
    "                    print(f\"Waiting directories (count: {len(web_dir_list)}):\\n\", web_dir_list[0], '...', web_dir_list[-1])\n",
    "                    \n",
    "                    \n",
    "                    new_folder = os.path.join(save_dir, local_dir)\n",
    "                    # os.makedirs(new_folder, exist_ok=True)\n",
    "                    \n",
    "                    if not os.path.exists(new_folder):\n",
    "                         os.makedirs(new_folder, exist_ok=True)    \n",
    "                    # new_folder = os.path.join(save_dir, save_dir_name)    \n",
    "                    # os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "                    # print(f'Creaet a folder {new_folder} for web directory: {full_web_dir}')\n",
    " \n",
    "                else:\n",
    "                    \n",
    "                    basename = item['name']     \n",
    "                    # if not 'spend' in basename:\n",
    "                    #     continue\n",
    "                    url = home_url + item['url']\n",
    "                    \n",
    "                    # skip data\n",
    "                    # if r'/ADVAN/' not in url:\n",
    "                    #     # print(\"Skipped:\", url)\n",
    "                    #     skipped_cnt += 1\n",
    "                    #     if skipped_cnt % 10 == 0:\n",
    "                    #         print(\"skipped un-targeted files:\", skipped_cnt)\n",
    "                    #     continue\n",
    "                    \n",
    "                    full_web_dir = home_url + web_dir\n",
    "                    local_dir = item['parent'].replace(init_url, '').replace(r'/', os.sep)[1:] # for windows  \n",
    "                    # print(\"save_dir, local_dir\", save_dir, local_dir, os.path.join(save_dir, local_dir))\n",
    "                    new_folder = os.path.join(save_dir, local_dir)\n",
    "                    # os.makedirs(new_folder, exist_ok=True)\n",
    "                    \n",
    "                    if not os.path.exists(new_folder):\n",
    "                         os.makedirs(new_folder, exist_ok=True)\n",
    "                    \n",
    "                    filename = os.path.join(new_folder, basename).replace(r'/', os.sep)  # for windows\n",
    "                    # print(\"new_folder, local_dir, filename, new_folder:\", new_folder, local_dir, filename, new_folder)\n",
    "                    \n",
    "                    # whether skip existing files:\n",
    "                    if not override:\n",
    "                        if os.path.exists(filename):\n",
    "                            # print(\"File exists, skipped:\", filename)\n",
    "                            skipped_cnt += 1\n",
    "                            if skipped_cnt % 50 == 0:\n",
    "                                print(\"skipped un-targeted files:\", skipped_cnt)\n",
    "                                print(\"File exists, skipped:\", filename)\n",
    "                            continue\n",
    "                            continue\n",
    "                    \n",
    "                    new_folder = os.path.dirname(filename)    \n",
    "                    os.makedirs(new_folder, exist_ok=True)\n",
    "                    \n",
    "                    print(f\"Downloading: {url}\")\n",
    "                    \n",
    "#                     with open(filename, 'wb') as f:\n",
    "                        \n",
    "#                         r = requests.get(url, stream=True, headers=headers)\n",
    "#                         f.write(r.content)\n",
    "                    r = requests.get(url, stream=True, headers=headers)\n",
    "                    safe_file_write(file_path=filename, content=r.content)\n",
    "        \n",
    "                    # with requests.get(url, stream=True, headers=headers) as r:\n",
    "                    #     # r.raise_for_status()\n",
    "                    #     with open(filename, 'wb') as f:\n",
    "                    #         for chunk in r.iter_content(chunk_size=8192):\n",
    "                    #             if chunk:\n",
    "                    #                 f.write(chunk)\n",
    "                    \n",
    "                    print(f\"Saved at  : {filename}\")\n",
    "                    \n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(url, e)\n",
    "            print(\"sleeping 5 seconds...\")\n",
    "            time.sleep(5)\n",
    "            \n",
    "            access_token = get_access_token()\n",
    "            headers = {\n",
    "            'accept': 'application/json',\n",
    "            'Authorization': f'Bearer {access_token}'\n",
    "              }\n",
    "            download_all_files(save_dir=save_dir, headers=headers)\n",
    "            \n",
    "            continue\n",
    "            \n",
    "    print(\"Done\")\n",
    "\n",
    "# Example usage\n",
    "# access_token = r'v8-YZaYSs3t9CYkKnYywgfQ8zIs'\n",
    "\n",
    "\n",
    "access_token = get_access_token()\n",
    "\n",
    "headers = {\n",
    "            'accept': 'application/json',\n",
    "            'Authorization': f'Bearer {access_token}'\n",
    "          }\n",
    "\n",
    "save_dir = r'G:\\SafeGraph_monthly_patterns_2018-2022'\n",
    "\n",
    "download_all_files(save_dir=save_dir, headers=headers)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kc6tBQL33V5u",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "b2ee03d3-b05d-4484-be1e-9e44354aafeb"
   },
   "outputs": [],
   "source": [
    "! echo -n \"hning@email.sc.edu:Nhww1898,\" | openssl base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -X 'POST' 'https://marketplace.deweydata.io/api/auth/tks/get_token' -H 'accept: application/json' -H 'Authorization: Basic LW4gImhuaW5nQGVtYWlsLnNjLmVkdTpOaHd3MTg5OCwiIA0K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYRsBFGX4OHj",
    "outputId": "ea1d396a-bbb0-4b61-e0e3-ce2ed7618054"
   },
   "outputs": [],
   "source": [
    "! curl -X GET \"https://marketplace.deweydata.io/api/data/v2/list\" -H \"accept: application/json\" -H \"Authorization: Bearer 0c3RBibybyGBMfXjOuCjO8qtxDA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "etsryACV8f7r",
    "outputId": "1743fd4d-c01a-4c38-fc2f-362fe62e1d67"
   },
   "outputs": [],
   "source": [
    "access_token = r'0c3RBibybyGBMfXjOuCjO8qtxDA'\n",
    "# ! path = r'api/data/v2/list/2022'\n",
    "# ! curl -H 'Accept: application/json' -H \"Authorization: Bearer 0c3RBibybyGBMfXjOuCjO8qtxDA\" -X GET 'https://marketplace.deweydata.io/api/data/v2/data/2022/12/01/SAFEGRAPH/MP/20221201-safegraph_mp_home_panel_0' -o test11.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iLuhdt_m8f2n",
    "outputId": "5fa2ef4e-ed62-4b65-d062-8d7a1ad300ee"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_all_files():\n",
    "    headers = {\n",
    "            'Accept': 'application/json',\n",
    "            'Authorization': 'Bearer 0c3RBibybyGBMfXjOuCjO8qtxDA'\n",
    "            }\n",
    "    res = requests.get(\n",
    "                        'https://marketplace.deweydata.io/api/data/v2/list',                     \n",
    "                    headers=headers)  \n",
    "    \n",
    "    print(res.url)\n",
    "    return res.json()\n",
    "\n",
    "dirs = get_all_files()\n",
    "dirs\n",
    "# open('visit_panel_summary2.csv', 'wb').write(res.content)\n",
    "url = r'https://marketplace.deweydata.io/api/data/v2/data/2022/12/01/SAFEGRAPH/MP/20221201-safegraph_mp_cpgp_part8_0'\n",
    "res = requests.get(\n",
    "                    url,                     \n",
    "                    headers=headers)  \n",
    "open('visit_panel_summary2.csv', 'wb').write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "def get_filename_from_cd(cd):\n",
    "    \"\"\"\n",
    "    Get filename from content-disposition\n",
    "    \"\"\"\n",
    "    if not cd:\n",
    "        return None\n",
    "    fname = re.findall('filename=(.+)', cd)\n",
    "    print(fname)\n",
    "    if len(fname) == 0:\n",
    "        return None\n",
    "    return fname[0]\n",
    "\n",
    "\n",
    "url = r'https://marketplace.deweydata.io/api/data/v2/data/2022/12/01/SAFEGRAPH/MP/20221201-safegraph_mp_cpgp_part8_0'\n",
    "\n",
    "# url = 'http://google.com/favicon.ico'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "filename = get_filename_from_cd(r.headers.get('content-disposition'))\n",
    "open(filename, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from posixpath import basename\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Main function\n",
    "def download_all_files(save_dir, headers):\n",
    " \n",
    "    init_url = r'/api/data/v2/list'\n",
    "    home_url = 'https://marketplace.deweydata.io'    \n",
    "    web_dir_list = [init_url]\n",
    "    \n",
    "    while len(web_dir_list) > 0:\n",
    "        try:\n",
    "            web_dir = web_dir_list.pop()\n",
    "            \n",
    "            \n",
    "            url = home_url + web_dir\n",
    "            # print(url, web_dir)\n",
    "            items = requests.get(url, headers=headers).json()\n",
    "            \n",
    "            items = items[::-1]\n",
    "            \n",
    "\n",
    "            for item in items:\n",
    "                name = item['name']\n",
    "                if item['directory']:  \n",
    "                    \n",
    "                    web_dir = item['url']\n",
    "                    \n",
    "                    full_web_dir = home_url + web_dir\n",
    "\n",
    "                    save_dir_name = full_web_dir.replace(home_url + init_url + '/', \"\").replace(r'/', '\\\\')  # for windows\n",
    "\n",
    "                    new_folder = os.path.join(save_dir, save_dir_name)    \n",
    "                    os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "                    web_dir_list.append(web_dir)    \n",
    "\n",
    "                    print(f'Creaet a folder {new_folder} for web directory: {full_web_dir}')\n",
    " \n",
    "                else:\n",
    "                    \n",
    "                    basename = item['name']     \n",
    "                    # if not 'spend' in basename:\n",
    "                    #     continue\n",
    "                    url = home_url + item['url']\n",
    "                    full_web_dir = home_url + web_dir\n",
    "                    local_dir = item['parent'].replace(init_url, '').replace(r'/', '\\\\')[1:] # for windows  \n",
    "                    # print(\"save_dir, local_dir\", save_dir, local_dir, os.path.join(save_dir, local_dir))\n",
    "                    new_folder = os.path.join(save_dir, local_dir)\n",
    "                    os.makedirs(new_folder, exist_ok=True)\n",
    "                    \n",
    "                    filename = os.path.join(new_folder, basename).replace(r'/', '\\\\')  # for windows\n",
    "                    # print(\"new_folder, local_dir, filename, new_folder:\", new_folder, local_dir, filename, new_folder)\n",
    "                    with requests.get(url, stream=True, headers=headers) as r:\n",
    "                        # r.raise_for_status()\n",
    "                        with open(filename, 'wb') as f:\n",
    "                            for chunk in r.iter_content(chunk_size=8192):\n",
    "                                if chunk:\n",
    "                                    f.write(chunk)\n",
    "                    print(f\"Downloaded: {url}\")\n",
    "                    print(f\"Saved at  : {filename}\")\n",
    "                    \n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(url, e)\n",
    "            print(\"sleeping 6 seconds...\")\n",
    "            time.sleep(6)\n",
    "            \n",
    "            continue\n",
    "\n",
    "# Example usage\n",
    "access_token = r'v8-YZaYSs3t9CYkKnYywgfQ8zIs'\n",
    "headers = {\n",
    "            'accept': 'application/json',\n",
    "            'Authorization': f'Bearer {access_token}'\n",
    "          }\n",
    "\n",
    "save_dir = r'L:\\SafeGraph_monthly_patterns_2018-2022'\n",
    "\n",
    "download_all_files(save_dir=save_dir, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "s6yJsmmbXYhM",
    "outputId": "d0a6b043-cfa7-482b-b3e3-9b7fcaa448e0"
   },
   "outputs": [],
   "source": [
    "# from posixpath import basename\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Function to download a file\n",
    "def download_file(home_url, item, save_folder, headers):\n",
    "\n",
    "    basename = item['name']\n",
    "    \n",
    "    \n",
    "    \n",
    "    url = home_url + item['url']\n",
    "    new_folder = os.path.join(save_folder, url.replace(home_url + '/', ''))\n",
    "    os.makedirs(new_folder, exist_ok=True)\n",
    "    \n",
    "    filename = os.path.join(new_folder, basename)\n",
    "    \n",
    "    with requests.get(url, stream=True, headers=headers) as r:\n",
    "        # r.raise_for_status()\n",
    "        with open(filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "    print(f\"Downloaded: {url}\")\n",
    "    print(f\"Saved at  : {filename}\")\n",
    "\n",
    "# Function to download a directory recursively\n",
    "def download_directory(directory, save_folder, headers):\n",
    "    home_url = 'https://marketplace.deweydata.io'\n",
    "    # print(\"directory: \", directory)\n",
    "    url = home_url + directory\n",
    "    # print(\"url:\", url)\n",
    "    items = requests.get(url, headers=headers).json()\n",
    "    \n",
    "    # print(\"headers:\", headers)\n",
    "    # print(url, items)\n",
    "\n",
    "    for item in items:\n",
    "        name = item['name']\n",
    "        # print(item)\n",
    "        # item_path = \n",
    "        \n",
    "        if item['directory']:\n",
    "            save_dir = os.path.join(save_folder, name)\n",
    "            # directory = home_url + \n",
    "            directory = item['url']\n",
    "            # print(\"directory: \", directory)\n",
    "            new_folder = os.path.join(save_folder, directory.replace(home_url, ''))\n",
    "            \n",
    "            os.makedirs(new_folder, exist_ok=True)\n",
    "            download_directory(directory, save_folder, headers=headers)\n",
    "        else:\n",
    "            download_file(home_url, item, save_folder, headers=headers)\n",
    "\n",
    "# Main function\n",
    "def download_all_files(save_folder):\n",
    "    headers = {\n",
    "        'accept': 'application/json',\n",
    "        'Authorization': 'Bearer 0c3RBibybyGBMfXjOuCjO8qtxDA'\n",
    "    }\n",
    "\n",
    "\n",
    "    download_directory(directory='/api/data/v2/list', save_folder=save_folder, headers=headers)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "save_dir = r'L:\\SafeGraph_monthly_patterns_2018-2022'\n",
    "download_all_files(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vrSNCOev8fvn",
    "outputId": "a8d8bfc2-1a9f-4227-dfd2-3afb031cff6c"
   },
   "outputs": [],
   "source": [
    "# files = res.json()\n",
    "\n",
    "type(files)\n",
    "files[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "id": "aeLoesOXMwxO",
    "outputId": "04ba75c7-5af0-4e75-ea92-e417e73267f8"
   },
   "outputs": [],
   "source": [
    "curl -H \"Accept: application/json\" -H \"Authorization: Bearer 0c3RBibybyGBMfXjOuCjO8qtxDA\" -X GET \"/api/data/v2/list/2022/12/01/SAFEGRAPH/MP/2022/12/01/SAFEGRAPH/MP/20221201-safegraph_mp_home_panel_0\" -o test42.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge panel CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_dir = r'F:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary_2023-11-23'\n",
    "\n",
    "\n",
    "def get_all_files(data_dir, exts=['.csv'], verbose=True):\n",
    "    all_files = []\n",
    "    for root_dir, folders, files in os.walk(data_dir):\n",
    "        \n",
    "        for f in files:\n",
    "            for ext in exts:\n",
    "                ext_len = len(ext)\n",
    "                if ext == f[-ext_len:]:\n",
    "                    full_name = os.path.join(root_dir, f)\n",
    "                    all_files.append(full_name)\n",
    "    if verbose:\n",
    "        print(\"Found files:\", len(all_files))\n",
    "    return sorted(all_files)\n",
    "\n",
    "\n",
    "all_files = get_all_files(data_dir, exts=['.csv.gz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_panel_df = pd.concat([pd.read_csv(f) for f in tqdm(all_files)])\n",
    "merged_panel_df = merged_panel_df.sort_values(['YEAR', 'MON', 'CENSUS_BLOCK_GROUP'])  \n",
    "merged_panel_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monthly_device_cnt_df = merged_panel_df.query(f\"ISO_COUNTRY_CODE == 'US' \").groupby(['YEAR', 'MON'], as_index=True)['NUMBER_DEVICES_RESIDING'].sum() / 10**6\n",
    "print(\"monthly_device_cnt_df   (million):\" )\n",
    "monthly_device_cnt_df = monthly_device_cnt_df.reset_index()\n",
    "monthly_device_cnt_df['year_month'] = monthly_device_cnt_df['YEAR'].astype(str)  + monthly_device_cnt_df['MON'].astype(str).str.zfill(2)\n",
    "monthly_device_cnt_df['year_month'] = pd.to_datetime(monthly_device_cnt_df['year_month'], format='%Y%m')\n",
    "monthly_device_cnt_df = monthly_device_cnt_df.set_index('year_month')\n",
    "monthly_device_cnt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_device_cnt_df.drop(columns=['YEAR', 'MON']).iloc[48:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_device_cnt_df['NUMBER_DEVICES_RESIDING'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help topic in Deweydata community\n",
    "\n",
    "https://community.deweydata.io/t/residing-device-count-in-2023-07-and-2023-08-surged-abnomorally/26675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_panel_df.query(f\"ISO_COUNTRY_CODE == 'US' and YEAR == 2023 and MON ==7 \")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
