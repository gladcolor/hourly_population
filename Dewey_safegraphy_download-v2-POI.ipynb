{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import base64 \n",
    "import tempfile\n",
    "from urllib.parse import urlparse\n",
    "from urllib.parse import unquote\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from getpass import getpass\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "access_token = 'ALtAyMZA.Y1sITQvTj6OXSr6XUz31P2ov3XvsdkhpbijDutzY0glCVNohhzM4okEe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_file_write(file_path, content):\n",
    "    # Create a temporary file in the same directory as the target file\n",
    "    dir_name = os.path.dirname(file_path)\n",
    "    with tempfile.NamedTemporaryFile(mode='wb', dir=dir_name, delete=False) as temp_file:\n",
    "        try:\n",
    "            # Write the content to the temporary file\n",
    "            temp_file.write(content)\n",
    "            temp_file.flush()\n",
    "            os.fsync(temp_file.fileno())\n",
    "            temp_file.close()\n",
    "\n",
    "            # Rename the temporary file to the target file (atomic operation)\n",
    "            os.replace(temp_file.name, file_path)\n",
    "        except Exception as e:\n",
    "            # Handle the exception (e.g., log it, raise it, or silently ignore it)\n",
    "            print(f\"An error occurred while writing the file: {e}\")\n",
    "            os.unlink(temp_file.name)\n",
    "        else:\n",
    "            print(\"File successfully written.\")\n",
    "\n",
    "def combine_monthly_pattern_home_panel_summary(data_dir, extend='.csv.gz'):\n",
    "    print(os.path.join(data_dir, f\"*{extend}\"))\n",
    "    all_files = glob(os.path.join(data_dir, f\"*{extend}\"))\n",
    "\n",
    "    df = pd.concat([pd.read_csv(f) for f in tqdm(all_files)])\n",
    "\n",
    "    return df\n",
    "    \n",
    "    # print(all_files)\n",
    "\n",
    "# Merge CSV files\n",
    "# home_panel_dir = r'F:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary'\n",
    "# home_panel_dir = r'F:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary_2023-11-23'\n",
    "# df = combine_monthly_pattern_home_panel_summary(data_dir=home_panel_dir)\n",
    "# df.to_csv(r'F:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_home_panel_summary_2019_2023.csv', index=False)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Spend patterns:\n",
    "# url = r'https://app.deweydata.io/external-api/v3/products/eb6e748a-0fdd-4bc7-9dd7-bbed0890948d/files'\n",
    "# # save_dir = r'K:\\SafeGraph\\Advan_2023_API\\Neighborhood_Patterns'   # Dell 2019\n",
    "# save_dir = r'D:\\SafeGraph\\Advan_2023_API\\Spend_Patterns'  # Lenova 2018\n",
    "\n",
    "# POI\n",
    "url = r'https://app.deweydata.io/external-api/v3/products/63eeb9d8-8439-42b3-a75e-2d9cbdf64cb8/files'\n",
    "save_dir = r'D:\\SafeGraph\\Advan_2023_API\\POI'  # Lenova 2018\n",
    "\n",
    "\n",
    "# neighborhood patterns:\n",
    "# url = r'https://app.deweydata.io/external-api/v3/products/2dfcb598-6e30-49f1-bdba-1deae113a951/files'\n",
    "# save_dir = r'K:\\SafeGraph\\Advan_2023_API\\Neighborhood_Patterns'   # Dell 2019\n",
    "# save_dir = r'F:\\SafeGraph\\Advan_2023_API\\Neighborhood_Patterns'  # Lenova 2018\n",
    "\n",
    "# monthly patterns:\n",
    "# url = r\"https://app.deweydata.io/external-api/v3/products/5acc9f39-1ca6-4535-b3ff-38f6b9baf85e/files\"\n",
    "# save_dir = r'K:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns'\n",
    "\n",
    "# # weekly patterns:\n",
    "# url = r\"https://app.deweydata.io/external-api/v3/products/176f0262-c1f6-4dbe-be43-6a6eb21bcf8a/files\"\n",
    "# save_dir = r'K:\\SafeGraph\\Advan_2023_API\\Weekly_Patterns'\n",
    "\n",
    "# # hourly weather:\n",
    "# url = r\"https://app.deweydata.io/external-api/v3/products/a6be0385-8820-4943-a509-6eac4154b4f6/files\"\n",
    "\n",
    "# monthly home panel summary\n",
    "# url = r'https://app.deweydata.io/external-api/v3/products/8546740c-b0e9-4556-abb9-4bea2cca9ac9/files'\n",
    "# save_dir = r'F:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary'\n",
    "\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "# set key and API endpoint variables\n",
    "API_KEY = access_token\n",
    "PRODUCT_API_PATH = url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(r'F:\\SafeGraph\\Advan_2023_API\\Monthly_Patterns_home_panel_summary\\Monthly_Patterns_home_panel_summary_2019_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = requests.get(url=PRODUCT_API_PATH,\n",
    "                                   params={'page': 1,\n",
    "                                           # 'partition_key_after': '2019-01-01',   # optionally set date value here\n",
    "                                           # 'partition_key_before': '2024-01-01', \n",
    "                                          }, # optionally set date value here\n",
    "                                   headers={'X-API-KEY': API_KEY,\n",
    "                                            'accept': 'application/json'\n",
    "                                           })\n",
    "response_json = results.json()\n",
    "# response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>partition_key</th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_extension</th>\n",
       "      <th>file_size_bytes</th>\n",
       "      <th>modified_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>NO</td>\n",
       "      <td>Global_Places_POI_Data-0.csv.gz</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>146193779</td>\n",
       "      <td>2024-01-07T20:48:47.561Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>NO</td>\n",
       "      <td>Global_Places_POI_Data-1.csv.gz</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>146282352</td>\n",
       "      <td>2024-01-07T20:48:47.556Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>NO</td>\n",
       "      <td>Global_Places_POI_Data-2.csv.gz</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>154391307</td>\n",
       "      <td>2024-01-07T20:48:47.574Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>NO</td>\n",
       "      <td>Global_Places_POI_Data-3.csv.gz</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>167781076</td>\n",
       "      <td>2024-01-07T20:48:47.563Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>NO</td>\n",
       "      <td>Global_Places_POI_Data-4.csv.gz</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>149519890</td>\n",
       "      <td>2024-01-07T20:48:47.566Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>NO</td>\n",
       "      <td>Global_Places_POI_Data-59.csv.gz</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>149649486</td>\n",
       "      <td>2024-01-07T20:48:45.446Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>NO</td>\n",
       "      <td>Global_Places_POI_Data-60.csv.gz</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>142311650</td>\n",
       "      <td>2024-01-07T20:48:45.436Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>NO</td>\n",
       "      <td>Global_Places_POI_Data-61.csv.gz</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>127156461</td>\n",
       "      <td>2024-01-07T20:48:45.435Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>NO</td>\n",
       "      <td>Global_Places_POI_Data-62.csv.gz</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>151423083</td>\n",
       "      <td>2024-01-07T20:48:45.436Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://s3.us-east-005.backblazeb2.com/amplify...</td>\n",
       "      <td>NO</td>\n",
       "      <td>Global_Places_POI_Data-63.csv.gz</td>\n",
       "      <td>.csv.gz</td>\n",
       "      <td>146154685</td>\n",
       "      <td>2024-01-07T20:48:45.437Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 link partition_key  \\\n",
       "0   https://s3.us-east-005.backblazeb2.com/amplify...            NO   \n",
       "0   https://s3.us-east-005.backblazeb2.com/amplify...            NO   \n",
       "0   https://s3.us-east-005.backblazeb2.com/amplify...            NO   \n",
       "0   https://s3.us-east-005.backblazeb2.com/amplify...            NO   \n",
       "0   https://s3.us-east-005.backblazeb2.com/amplify...            NO   \n",
       "..                                                ...           ...   \n",
       "0   https://s3.us-east-005.backblazeb2.com/amplify...            NO   \n",
       "0   https://s3.us-east-005.backblazeb2.com/amplify...            NO   \n",
       "0   https://s3.us-east-005.backblazeb2.com/amplify...            NO   \n",
       "0   https://s3.us-east-005.backblazeb2.com/amplify...            NO   \n",
       "0   https://s3.us-east-005.backblazeb2.com/amplify...            NO   \n",
       "\n",
       "                           file_name file_extension  file_size_bytes  \\\n",
       "0    Global_Places_POI_Data-0.csv.gz        .csv.gz        146193779   \n",
       "0    Global_Places_POI_Data-1.csv.gz        .csv.gz        146282352   \n",
       "0    Global_Places_POI_Data-2.csv.gz        .csv.gz        154391307   \n",
       "0    Global_Places_POI_Data-3.csv.gz        .csv.gz        167781076   \n",
       "0    Global_Places_POI_Data-4.csv.gz        .csv.gz        149519890   \n",
       "..                               ...            ...              ...   \n",
       "0   Global_Places_POI_Data-59.csv.gz        .csv.gz        149649486   \n",
       "0   Global_Places_POI_Data-60.csv.gz        .csv.gz        142311650   \n",
       "0   Global_Places_POI_Data-61.csv.gz        .csv.gz        127156461   \n",
       "0   Global_Places_POI_Data-62.csv.gz        .csv.gz        151423083   \n",
       "0   Global_Places_POI_Data-63.csv.gz        .csv.gz        146154685   \n",
       "\n",
       "                 modified_at  \n",
       "0   2024-01-07T20:48:47.561Z  \n",
       "0   2024-01-07T20:48:47.556Z  \n",
       "0   2024-01-07T20:48:47.574Z  \n",
       "0   2024-01-07T20:48:47.563Z  \n",
       "0   2024-01-07T20:48:47.566Z  \n",
       "..                       ...  \n",
       "0   2024-01-07T20:48:45.446Z  \n",
       "0   2024-01-07T20:48:45.436Z  \n",
       "0   2024-01-07T20:48:45.435Z  \n",
       "0   2024-01-07T20:48:45.436Z  \n",
       "0   2024-01-07T20:48:45.437Z  \n",
       "\n",
       "[64 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_download_urls():\n",
    "    total_pages = 1\n",
    "    current_page = 0\n",
    "    df_list = []\n",
    "    while current_page < total_pages:\n",
    "        results = requests.get(url=PRODUCT_API_PATH,\n",
    "                                   params={'page': total_pages,\n",
    "                                           # 'partition_key_after': '2017-01-01',   # optionally set date value here\n",
    "                                           # 'partition_key_before': '2024-12-31', \n",
    "                                          }, # optionally set date value here\n",
    "                                   headers={'X-API-KEY': API_KEY,\n",
    "                                            'accept': 'application/json'\n",
    "                                           })\n",
    "        response_json = results.json()\n",
    "        total_pages = response_json['total_pages']\n",
    "    \n",
    "        df = pd.DataFrame(response_json)\n",
    "        df_list.append(df)\n",
    "        current_page += 1\n",
    "            \n",
    "    response_df = pd.concat(df_list)\n",
    "    \n",
    "    \n",
    "    df_list2 = []\n",
    "    for idx, row in response_df.iterrows():\n",
    "        # print(row['download_links'])\n",
    "        df = pd.DataFrame.from_dict([row['download_links']])\n",
    "        df_list2.append(df)\n",
    "        # break\n",
    "        \n",
    "    url_df = pd.concat(df_list2).sort_values(\"partition_key\")\n",
    "    return response_df, url_df\n",
    "\n",
    "response_df, url_df = get_all_download_urls()\n",
    "url_df['partition_key'] = \"NO\"\n",
    "url_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_df['partition_key'] = url_df['modified_at'].str[:10]\n",
    "# url_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year, month, day: 2024 01 07\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\POI\\2024\\01\\07\\Global_Places_POI_Data-0_2024-01-07.csv.gz\n",
      "File successfully written.\n",
      "    Downloaded 1 / 64 files for NO.\n",
      "Downloaded 1 / 64 files in total.\n",
      "\n",
      "Year, month, day: 2024 01 07\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\POI\\2024\\01\\07\\Global_Places_POI_Data-1_2024-01-07.csv.gz\n",
      "File successfully written.\n",
      "    Downloaded 2 / 64 files for NO.\n",
      "Downloaded 2 / 64 files in total.\n",
      "\n",
      "Year, month, day: 2024 01 07\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\POI\\2024\\01\\07\\Global_Places_POI_Data-2_2024-01-07.csv.gz\n",
      "File successfully written.\n",
      "    Downloaded 3 / 64 files for NO.\n",
      "Downloaded 3 / 64 files in total.\n",
      "\n",
      "Year, month, day: 2024 01 07\n",
      "Downloading file D:\\SafeGraph\\Advan_2023_API\\POI\\2024\\01\\07\\Global_Places_POI_Data-3_2024-01-07.csv.gz\n"
     ]
    }
   ],
   "source": [
    "downloaded_cnt = 0\n",
    "for partition_key, df in url_df.groupby('partition_key'):\n",
    "   \n",
    "    df = df.reset_index()\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            # print(partition_key, i + 1)\n",
    "            # print(\"Downloading: \", row['link'])\n",
    "            date = row['modified_at'][:10]\n",
    "            year = date[:4]\n",
    "            month = date[5:7]\n",
    "            day = date[-2:]\n",
    "            file_dir = os.path.join(save_dir, year, month, day)\n",
    "            os.makedirs(file_dir, exist_ok=True)\n",
    "            print(\"Year, month, day:\", year, month, day)\n",
    "    \n",
    "            # base_name = row['file_name']\n",
    "            base_name = row['file_name'][:-7] +  f\"_{date}.csv.gz\"\n",
    "            # print(\"base_name:\", base_name)\n",
    "            \n",
    "            file_name = os.path.join(file_dir, base_name)\n",
    "             \n",
    "            print(f'Downloading file {file_name}')\n",
    "        \n",
    "            if os.path.exists(file_name):\n",
    "                print(f\"File exists, skip! The file is: {file_name} \\n\")\n",
    "                continue\n",
    "        \n",
    "            # # loop through download links and save to your computer\n",
    "            data = requests.get(row['link'], stream=True)\n",
    "            safe_file_write(file_path=file_name, content=data.content)\n",
    "             \n",
    "            #  += 1\n",
    "            downloaded_cnt += 1\n",
    "            print(f\"    Downloaded {i + 1} / {len(df)} files for {partition_key}.\")\n",
    "            print(f\"Downloaded {downloaded_cnt} / {len(url_df)} files in total.\")\n",
    "            # print(f\"Downloaded {download_count} files in total, Page {page} / {total_pages}.\")\n",
    "            \n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            continue\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3138096080.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[25], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    Not used below\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# STOP\n",
    "\n",
    "# Not used below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "id": "aeLoesOXMwxO",
    "outputId": "04ba75c7-5af0-4e75-ea92-e417e73267f8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"D:\\SafeGraph\\Advan_2023_API\\POI\\2024\\01\\07\"\n",
    "save_dir = r'D:\\SafeGraph\\Advan_2023_API\\POI\\2024\\01\\07'\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File count: 64\n",
      "D:\\SafeGraph\\Advan_2023_API\\POI\\2024\\01\\07\\Global_Places_POI_Data-0Global_Places_POI_Data-0_1.csv.gz\n",
      "D:\\SafeGraph\\Advan_2023_API\\POI\\2024\\01\\07\\Global_Places_POI_Data-9Global_Places_POI_Data-9_10.csv.gz\n"
     ]
    }
   ],
   "source": [
    "all_files = glob(os.path.join(data_dir, \"*.gz\"))\n",
    "print(\"File count:\", len(all_files))\n",
    "print(all_files[0])\n",
    "print(all_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "use_cols = ['PLACEKEY', 'TOP_CATEGORY', 'SUB_CATEGORY', 'NAICS_CODE', 'CITY', 'REGION', 'POSTAL_CODE', 'ISO_COUNTRY_CODE']\n",
    "\n",
    "for idx, f in enumerate(all_files):\n",
    "    print(f\"Processing: {idx + 1} / {len(all_files)}, \", os.path.basename(f))\n",
    "    df = pd.read_csv(f, usecols=use_cols)\n",
    "    t_df = df[df['ISO_COUNTRY_CODE'].isin(countries)] \n",
    "    # t_df = df[df['NAICS_CODE'].isin(target_NAICS)]\n",
    "    # t_df = t_df[t_df['CITY'].isin(target_city)]\n",
    "    # t_df = t_df[t_df['REGION'].isin(target_region)]\n",
    "    \n",
    "    df_list.append(t_df)\n",
    "    # break\n",
    "\n",
    "df_all = pd.concat(df_list)\n",
    "fname = os.path.join(save_dir, 'megerd_POI_20240107.csv')\n",
    "df_all.to_csv(fname, index=False)\n",
    "# print(\"Saved at:\", fname)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help topic in Deweydata community\n",
    "\n",
    "https://community.deweydata.io/t/residing-device-count-in-2023-07-and-2023-08-surged-abnomorally/26675"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
